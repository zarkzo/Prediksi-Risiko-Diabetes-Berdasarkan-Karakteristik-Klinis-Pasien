# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kjOqfvQIW6ocHZvgFxK3rKOCDEBZ7Oep

# Proyek Prediksi Risiko Diabetes Berdasarkan Karakteristik Klinis Pasien
- **Nama:** Putra Faaris Prayoga
- **Email:** putrafaariz47@gmail.com
- **ID Dicoding:** putra_faaris

## Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_selection import RFE
from imblearn.over_sampling import SMOTE
from scipy.stats import zscore

"""## Loading data

"""

# Load the dataset
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
data = pd.read_csv(url, names=columns)

data.head()

"""## Preprocessing

### cleaning
"""

data.info()

print("Cek nilai null pada data:\n", data.isnull().sum())  # Menampilkan jumlah nilai null pada setiap kolom

print("\nCek duplikat pada data:\n", data.duplicated().sum())  # Menampilkan jumlah duplikat dalam dataset

# Deteksi Outlier menggunakan Z-Score
z_scores = np.abs(zscore(data.drop('Outcome', axis=1)))

# Tentukan ambang batas Z-Score (misalnya lebih besar dari 3 dianggap sebagai outlier)
threshold = 3
outliers = (z_scores > threshold)

# Menampilkan jumlah outlier di setiap kolom
outliers_count = np.sum(outliers, axis=0)
print("\nJumlah outlier di setiap fitur:")
print(outliers_count)

# Mengurus Outlier: Menghapus baris yang mengandung outlier
data = data[~(outliers.any(axis=1))]  # Menghapus baris yang memiliki outlier

# Deteksi Outlier menggunakan Z-Score
z_scores = np.abs(zscore(data.drop('Outcome', axis=1)))

# Tentukan ambang batas Z-Score (misalnya lebih besar dari 3 dianggap sebagai outlier)
threshold = 3
outliers = (z_scores > threshold)

# Menampilkan jumlah outlier di setiap kolom
outliers_count = np.sum(outliers, axis=0)
print("\nJumlah outlier di setiap fitur:")
print(outliers_count)

"""### EDA

"""

# 1. Data info
data.describe()

# 2. Heatmap untuk melihat korelasi antar fitur
plt.figure(figsize=(10, 8))
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Heatmap Korelasi Antar Fitur')
plt.show()

# 3. Bar Chart untuk distribusi data (Diabetes vs Tidak Diabetes)
plt.figure(figsize=(8, 6))
data['Outcome'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'], alpha=0.7)
plt.title('Distribusi Pasien dengan dan Tanpa Diabetes')
plt.xticks(ticks=[0, 1], labels=['No Diabetes', 'Diabetes'], rotation=0)
plt.ylabel('Jumlah Pasien')
plt.show()

"""### oversampling

"""

# Menyeimbangkan dataset menggunakan SMOTE
X = data.drop('Outcome', axis=1)
y = data['Outcome']

# SMOTE untuk menyeimbangkan data
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Cek distribusi setelah SMOTE
print("\nDistribusi setelah SMOTE:\n", y_resampled.value_counts())

"""### Normalisiasi data"""

# Pilih salah satu normalisasi
scaler = MinMaxScaler()  # Bisa juga diganti dengan StandardScaler untuk Z-Score normalization
X_resampled_scaled = scaler.fit_transform(X_resampled)

"""### Feature Selection - Menggunakan RFE (Recursive Feature Elimination)"""

model = LogisticRegression()  # Bisa menggunakan model lain seperti RandomForestClassifier
selector = RFE(model, n_features_to_select=5)  # Memilih 5 fitur terbaik
X_selected = selector.fit_transform(X_resampled_scaled, y_resampled)

"""### Spliting"""

# Split data yang sudah diseimbangkan menjadi train dan test
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

"""## Model

"""

# Models to evaluate
models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "KNN": KNeighborsClassifier()
}

# Evaluate each model
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy

# Display results as a bar chart
plt.figure(figsize=(10, 6))
plt.bar(results.keys(), results.values(), color='skyblue')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Perbandingan Akurasi Model')
plt.show()

# Best Model Evaluation - Random Forest
best_model = RandomForestClassifier()
best_model.fit(X_train, y_train)
y_pred_best = best_model.predict(X_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_best)

# Display Confusion Matrix as Heatmap
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Display classification report
print(classification_report(y_test, y_pred_best))